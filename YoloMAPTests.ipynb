{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo Mean Average Precision\n",
    "The purpose of this notebook is to calculate mAP for each of the YOLOv8 models. The mAP@[0.5:0.95:0.05] will be calculated for each class and the results will be saved to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commonPaths\n",
    "import commonCocoPreprocessingFunctions as preprocFuncs\n",
    "import ScoreCalculator\n",
    "from importlib import reload\n",
    "reload(commonPaths)\n",
    "reload(preprocFuncs)\n",
    "reload(ScoreCalculator)\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import math as m\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeGroundTruthBoxesForImg(annotYoloJSONFilePath):\n",
    "    '''\n",
    "        ### reshapeGroundTruthBoxesForImg\n",
    "        :param annotYoloJSONFilePath: Path to JSON file containing GroundTruth Boxes in the YOLO format\n",
    "        (the file produced by the createAnnotJSONForYolo function). The format should be like this:\n",
    "        {\"imageId\": [ {\"yoloCatId\": ycId, \"bbox\": [xMid, yMid, width, height]}, {(...)anotherAnnot(...)} ]}\n",
    "        :return: a list containing groundTruth boxes for image. Each element in a list is a list of groundTruth\n",
    "        boxes for the given image (written in the YOLO format [imgId, class, xMid, yMid, width, height]).\n",
    "        It is not a dictionary since the results in the results given by YOLO models are in the same order\n",
    "        as files in the directory.\n",
    "    '''\n",
    "    gtsFile= open(annotYoloJSONFilePath)\n",
    "    groundTruthsJSON = json.load(gtsFile)\n",
    "    groundTruths = []\n",
    "    for imgId, annots in groundTruthsJSON.items():\n",
    "        groundTruthsForImg = []\n",
    "        for ann in annots:\n",
    "            gtClass = ann[\"yoloCatId\"]\n",
    "            bbox = ann[\"bbox\"]\n",
    "            groundTruthBox = [int(imgId), gtClass, bbox[0], bbox[1], bbox[2], bbox[3]]\n",
    "            groundTruthsForImg.append(groundTruthBox)\n",
    "        groundTruths.append(groundTruthsForImg)\n",
    "    return groundTruths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFrameHeader(annotDir, annotFileName):\n",
    "    '''\n",
    "        ### createDataFrameHeader\n",
    "        creates column names for data frames used to store calculated APs for each batch for each class.\n",
    "\n",
    "        :param annotDir: directory with annotations for the given dataset\n",
    "        :param annotFileName: file name with annotations in the given directory (used to retrieve info about classes)\n",
    "        :return: a list of column names corresponding to the classes within the dataset\n",
    "    '''\n",
    "    instancesJSON = preprocFuncs.getInstancesAsJSON(annotDir, annotFileName)\n",
    "    categoryIdToNameAndYoloId = preprocFuncs.associateCategoryIdWithItsNameAndYoloId(instancesJSON)\n",
    "    columnNames = []\n",
    "    for cat in categoryIdToNameAndYoloId.values():\n",
    "        columnNames.append(f\"{cat.categoryName} {cat.yoloId}\".replace(\" \", \"_\"))\n",
    "    return columnNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateIoUThresholds(minIoU, maxIoU, stepIoU):\n",
    "    '''\n",
    "        ### calculateIoUThresholds\n",
    "        creates a range of IoU thresholds from the given min, max and step IoU\n",
    "\n",
    "        :param minIoU: minimum threshold for which to start calculating\n",
    "        :param maxIoU: maximum threshold for which to stop calculating\n",
    "        :param stepIoU: step for how much to increase IoU threshold in each iteration\n",
    "        :return: list containing all IoU thresholds for which to calculate APs\n",
    "    '''\n",
    "    iouThresholds = []\n",
    "    for i in range( int(minIoU*100), int((maxIoU+stepIoU)*100), int(stepIoU*100)):\n",
    "        iouThresholds.append(i/100)\n",
    "    return iouThresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictResultsAndCalculatemAPForEachClass(model, pathsToImgs, batchSize, columnNames, groundTruths, iouThresholds):\n",
    "    '''\n",
    "        ### predictResultsAndCalculatemAPForEachClass\n",
    "        The function uses the model to predict bboxes and then calculates mAP for each class. \n",
    "        mAP is calculated for IoU thresholds from the range given by the params. The mAP is calculated for\n",
    "        several batches since not dividing in batches is difficult computationally. The function returns\n",
    "        calculated mAP for each class. To calculate final mAP one would have to average the results for the number\n",
    "        of classes.\n",
    "\n",
    "        :param model: YOLO model on which predictions should be made\n",
    "        :param pathsToImgs: a list with paths to imgs. (e.g. result of preprocFuncs.providePathsToImages)\n",
    "        :param batchSize: The size of a batch for dividing the dataset in smaller parts.\n",
    "        :param columnNames: a list of column names for the output series. (e.g. result of createDataFrameHeader)\n",
    "        :param groundTruths: list of list of groundTruth boxes for each Image. Boxes should be in the YOLO format\n",
    "        (e.g. result of reshapeGroundTruthBoxesForImg)\n",
    "        :param iouThresholds: a list of IoU thresholds for which to calculate APs (e.g. result of calculateIoUThresholds)\\\n",
    "        \n",
    "        :return: a data series with mean Average Precisions for each class.\n",
    "    '''\n",
    "    noBatches = m.ceil(len(pathsToImgs) / batchSize)\n",
    "    averagePrecisionsForIOUThreshold = []\n",
    "    for i in iouThresholds:\n",
    "        averagePrecisionsForIOUThreshold.append(pd.DataFrame(columns=columnNames))\n",
    "\n",
    "    for i in tqdm(range(0,noBatches)):\n",
    "        start = i * batchSize\n",
    "        end = (start + batchSize) if (start + batchSize) < len(pathsToImgs) else len(pathsToImgs)\n",
    "        results = model.predict(pathsToImgs[start:end], verbose=False, device=\"0\")\n",
    "        predictedBoxes = []\n",
    "        for result in results:\n",
    "            imgId = int(result.path.split(\"/\")[-1].split(\".\")[0])\n",
    "            for bbox in result.boxes:\n",
    "                predClass = int(bbox.cls)\n",
    "                predConf = round(float(bbox.conf),6)\n",
    "                predBbox = bbox.xywhn\n",
    "                x = round(predBbox[0][0].item(),6)\n",
    "                y = round(predBbox[0][1].item(),6)\n",
    "                width = round(predBbox[0][2].item(),6)\n",
    "                height = round(predBbox[0][3].item(),6)\n",
    "                predictedBox = [imgId, predClass, x, y, width, height, predConf]\n",
    "                predictedBoxes.append(predictedBox)\n",
    "        groundTruthsToPass = []\n",
    "        for gtList in groundTruths[start:end]:\n",
    "            groundTruthsToPass.extend(gtList)\n",
    "\n",
    "        for j, avgPrecisionForBatch in enumerate(averagePrecisionsForIOUThreshold):\n",
    "            iouThresh = iouThresholds[j]\n",
    "            avgPrecisionForBatch.loc[len(avgPrecisionForBatch.index)] = ScoreCalculator.meanAveragePrecission(predictedBoxes, groundTruthsToPass, iouThreshold=iouThresh)\n",
    "\n",
    "    apsForClasses = pd.DataFrame(columns=columnNames)\n",
    "    for frame in averagePrecisionsForIOUThreshold:\n",
    "        apsForClasses.loc[len(apsForClasses.index)] = frame.sum(axis=0)\n",
    "    mapsForClasses = (apsForClasses.sum() / (noBatches * len(averagePrecisionsForIOUThreshold) ))\n",
    "    return mapsForClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveResults(calculatedMAPsForEachClass, modelName, batchSize, minIoU, maxIoU, stepIoU, pathToOutFile):\n",
    "    '''\n",
    "        ### saveResults\n",
    "        saves results in the given directory. \n",
    "        The file name is mAPResults_{batchSize}_{minIoU}_{maxIoU}_{stepIoU}_{modelName}.csv\n",
    "\n",
    "        :param calculatedMAPsForEachClass: mAPs for each class (e.g. result of predictResultsAndCalculatemAPForEachClass)\n",
    "        :param modelName: name of the model\n",
    "        :param batchSize: The size of a batch for dividing the dataset in smaller parts.\n",
    "        :param minIoU: minimum threshold for which to start calculating\n",
    "        :param maxIoU: maximum threshold for which to stop calculating\n",
    "        :param stepIoU: step for how much to increase IoU threshold in each iteration\n",
    "        :param pathToOutFile: the directory where to write file (with trailing slash)\n",
    "    '''\n",
    "    outPath = pathToOutFile\n",
    "    outPath+=f\"MAPResults_{batchSize}_{minIoU}_{maxIoU}_{stepIoU}_{modelName}.csv\"\n",
    "    if(os.path.isfile(outPath)):\n",
    "            msg = f\"Results file already exists at \\\"{outPath}\\\"\"\n",
    "            raise Exception(msg)\n",
    "    calculatedMAPsForEachClass.to_csv(outPath, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMeanAvgPrecisionsForClassForModel(model, batchSize, minIoU, maxIoU, stepIoU, isTrain=False):\n",
    "    '''\n",
    "        ### calculateMeanAvgPrecisionsForClassForModel\n",
    "        function to calculate mean average precisions for each class for the given model.\n",
    "\n",
    "        :param model: YOLO model on which predictions should be made\n",
    "        :param batchSize: The size of a batch for dividing the dataset in smaller parts.\n",
    "        :param minIoU: minimum threshold for which to start calculating\n",
    "        :param maxIoU: maximum threshold for which to stop calculating\n",
    "        :param stepIoU: step for how much to increase IoU threshold in each iteration\n",
    "        :param isTrain: whether to calculate mAP on train or val dataset. (Set to False by default)\n",
    "\n",
    "        :return: a data series with mean Average Precisions for each class.\n",
    "    '''\n",
    "    pathsDict = preprocFuncs.providePaths(isTrain)\n",
    "    pathsToImgs = preprocFuncs.providePathsToImages(pathsDict[\"COCO_IMG_DIR\"])\n",
    "    groundTruths = reshapeGroundTruthBoxesForImg(pathsDict[\"ANNOT_YOLO_JSON_FILE\"])\n",
    "    columnNames = createDataFrameHeader(pathsDict[\"COCO_ANNOT_DIR\"], pathsDict[\"ANNOT_FILENAME\"])\n",
    "    iouThresholds = calculateIoUThresholds(minIoU, maxIoU, stepIoU)\n",
    "    calculatedMAPsForEachClass = predictResultsAndCalculatemAPForEachClass(model, pathsToImgs, batchSize, columnNames, groundTruths, iouThresholds)\n",
    "    saveResults(calculatedMAPsForEachClass.astype(float), model.model_name, batchSize, minIoU, maxIoU, stepIoU, pathsDict[\"MAP_RESULTS_DIR\"])\n",
    "    return calculatedMAPsForEachClass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:08<00:00,  6.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "person_0         tensor(0.4494)\n",
       "bicycle_1        tensor(0.3154)\n",
       "car_2            tensor(0.3181)\n",
       "motorcycle_3     tensor(0.3802)\n",
       "airplane_4       tensor(0.6797)\n",
       "                      ...      \n",
       "vase_75          tensor(0.3334)\n",
       "scissors_76      tensor(0.7478)\n",
       "teddy_bear_77    tensor(0.4649)\n",
       "hair_drier_78    tensor(0.8400)\n",
       "toothbrush_79    tensor(0.5053)\n",
       "Length: 80, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateMeanAvgPrecisionsForClassForModel(model, 100, 0.5, 0.95, 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
